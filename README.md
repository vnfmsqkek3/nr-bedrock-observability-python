# New Relic AWS Bedrock Observability for Python

AWS Bedrock API í˜¸ì¶œì„ ëª¨ë‹ˆí„°ë§í•˜ê³  ì„±ëŠ¥ ì§€í‘œë¥¼ New Relicì— ì „ì†¡í•˜ëŠ” ë¼ì´ë¸ŒëŸ¬ë¦¬ì…ë‹ˆë‹¤.

## ìµœì‹  ì—…ë°ì´íŠ¸ (v1.3.0)

- **Streamlit í”¼ë“œë°± ê¸°ëŠ¥ ì¶”ê°€**:
  - Streamlit ì• í”Œë¦¬ì¼€ì´ì…˜ì—ì„œ ì‚¬ìš©ì í”¼ë“œë°±ì„ ì‰½ê²Œ ìˆ˜ì§‘
  - ì‹œê°ì ì¸ í”¼ë“œë°± UI ì»´í¬ë„ŒíŠ¸ ì œê³µ (ê¸ì •, ì¤‘ë¦½, ë¶€ì • ë°˜ì‘)
  - ì‚¬ìš©ì í”¼ë“œë°± ë°ì´í„°ë¥¼ New Relicì— ìë™ ì „ì†¡
  - í”¼ë“œë°± ë°ì´í„°ì™€ LLM ì‘ë‹µ íŠ¸ë ˆì´ìŠ¤ ìë™ ì—°ê²°

- **ì—­í• ë³„ ë©”ì‹œì§€ ë¶„ë¦¬ ê¸°ëŠ¥ (v1.2.0)**:
  - ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ë¥¼ ë³„ë„ì˜ ì´ë²¤íŠ¸ë¡œ ë¶„ë¦¬í•˜ì—¬ ê¸°ë¡
  - ì‚¬ìš©ì í”„ë¡¬í”„íŠ¸ë¥¼ ë³„ë„ì˜ ì´ë²¤íŠ¸ë¡œ ë¶„ë¦¬í•˜ì—¬ ê¸°ë¡
  - OpenSearch ê²€ìƒ‰ ê²°ê³¼ë¥¼ ë³„ë„ì˜ ì´ë²¤íŠ¸ë¡œ ë¶„ë¦¬í•˜ì—¬ ê¸°ë¡
  - RAG ì»¨í…ìŠ¤íŠ¸ë¥¼ ë³„ë„ì˜ ì´ë²¤íŠ¸ë¡œ ë¶„ë¦¬í•˜ì—¬ ê¸°ë¡

## ì—…ë°ì´íŠ¸ íˆìŠ¤í† ë¦¬

### v1.3.0
- Streamlit ì• í”Œë¦¬ì¼€ì´ì…˜ì—ì„œ ì‚¬ìš©ì í”¼ë“œë°±ì„ ì‰½ê²Œ ìˆ˜ì§‘í•˜ëŠ” ê¸°ëŠ¥ ì¶”ê°€
- ì‹œê°ì ì¸ í”¼ë“œë°± UI ì»´í¬ë„ŒíŠ¸ ì œê³µ (ê¸ì •, ì¤‘ë¦½, ë¶€ì • ë°˜ì‘)
- í”¼ë“œë°± ë°ì´í„°ë¥¼ New Relicì— ìë™ ì „ì†¡ ë° LLM ì‘ë‹µ íŠ¸ë ˆì´ìŠ¤ì™€ ì—°ê²°
- ìƒ˜í”Œ Streamlit ì• í”Œë¦¬ì¼€ì´ì…˜ ì œê³µ

### v1.2.0
- ì—­í• ë³„ ë©”ì‹œì§€ ë¶„ë¦¬ ê¸°ëŠ¥ ì¶”ê°€ (ì‹œìŠ¤í…œ/ì‚¬ìš©ì í”„ë¡¬í”„íŠ¸, OpenSearch ê²°ê³¼, RAG ì»¨í…ìŠ¤íŠ¸)
- ì „ì²´ ì›Œí¬í”Œë¡œìš° íŠ¸ë ˆì´ì‹± ì—°ê²° ê¸°ëŠ¥ ê°œì„ 
- New Relic NRQL ì¿¼ë¦¬ë¥¼ í†µí•œ ë¶„ì„ ì§€ì›

### v1.1.2
- Streamlit í™˜ê²½ì—ì„œ ë°œìƒí•˜ëŠ” "Attempt to save a trace from an inactive transaction" ì˜¤ë¥˜ í•´ê²°
- ê° API í˜¸ì¶œ ì „ì— í˜„ì¬ í™œì„± íŠ¸ëœì­ì…˜ í™•ì¸
- í™œì„± íŠ¸ëœì­ì…˜ì´ ì—†ëŠ” ê²½ìš°ì—ë§Œ ìƒˆ íŠ¸ëœì­ì…˜ ìƒì„±
- íŠ¸ëœì­ì…˜ ì‹œì‘ê³¼ ì¢…ë£Œë¥¼ ëª…í™•í•˜ê²Œ ê´€ë¦¬ ë° ì˜ˆì™¸ ì²˜ë¦¬ ê°•í™”

### v1.1.1
- Streamlit í™˜ê²½ì—ì„œì˜ New Relic íŠ¸ëœì­ì…˜ ê´€ë¦¬ ê°œì„ 
- ë©€í‹°ìŠ¤ë ˆë”© í™˜ê²½ì—ì„œì˜ íŠ¸ëœì­ì…˜ ì²˜ë¦¬ ì•ˆì •ì„± í–¥ìƒ
- ë¹„í™œì„± íŠ¸ëœì­ì…˜ ì €ì¥ ì‹œë„ë¡œ ì¸í•œ ì—ëŸ¬ ë°©ì§€
- íŠ¸ëœì­ì…˜ ì´ˆê¸°í™” ë° ì¢…ë£Œ ì‹œ ì˜ˆì™¸ ì²˜ë¦¬ ê°•í™”

### v1.1.0
- ì‚¬ìš©ì í”¼ë“œë°± ìˆ˜ì§‘ ê¸°ëŠ¥ ì¶”ê°€
- í”¼ë“œë°± íƒ€ì… ì§€ì› (positive, negative, neutral)
- ê°ì • ì ìˆ˜ ì§€ì› (-1.0 ~ 1.0)
- í”¼ë“œë°± ë©”ì‹œì§€ ìˆ˜ì§‘ ê¸°ëŠ¥
- í”¼ë“œë°± ì½œë°± í•¨ìˆ˜ë¥¼ í†µí•œ ì‚¬ìš©ì ì •ì˜ í”¼ë“œë°± ìˆ˜ì§‘ ì§€ì›
- New Relic ì´ë²¤íŠ¸ì— í”¼ë“œë°± ë°ì´í„° ìë™ í¬í•¨

### v1.0.3
- Claude 3.5 Sonnet v2 ìµœì‹  ë²„ì „(anthropic.claude-3-5-sonnet-20241022-v2:0) ëª¨ë¸ ì§€ì› ê°•í™”
- ë‚´ë¶€ ëª¨ë¸ ë§µí•‘ í…Œì´ë¸”ì˜ ì¼ê´€ì„± ê°œì„ 
- ëª¨ë“  ëª¨ë“ˆì—ì„œ ì‹ ê·œ ëª¨ë¸ ID ì¸ì‹ ê°€ëŠ¥í•˜ë„ë¡ ì—…ë°ì´íŠ¸
- RAG ì›Œí¬í”Œë¡œìš° íŠ¸ë ˆì´ì‹± ìƒ˜í”Œ ì½”ë“œ ì¶”ê°€: ì‚¬ìš©ì ì§ˆë¬¸ â†’ OpenSearch ê²€ìƒ‰ â†’ Bedrock LLM ì‘ë‹µì„ í•˜ë‚˜ì˜ íŠ¸ë ˆì´ìŠ¤ë¡œ ì—°ê²°

### v1.0.2
- Claude 3.5 Sonnet ìµœì‹  ë²„ì „(anthropic.claude-3-5-sonnet-20241022-v2:0) ì§€ì› ì¶”ê°€
- ëª¨ë¸ ID ì¶”ì  ë° ì¸ì‹ ê¸°ëŠ¥ ê°œì„ 
- ë‚´ë¶€ ëª¨ë¸ ë§¤í•‘ í…Œì´ë¸” ì—…ë°ì´íŠ¸

### v1.0.1
- ì•ˆì •ì„± ê°•í™” ë° ë‚´ë¶€ ì˜¤ë¥˜ ì²˜ë¦¬ ê°œì„ 
- Streaming ì‘ë‹µì„ ì²˜ë¦¬í•œ í›„ì—ë„ ì‘ë‹µ ë³¸ë¬¸ì„ ë³´ì¡´ ê°€ëŠ¥í•˜ë„ë¡ êµ¬ì¡° ë³€ê²½
- `StreamingBody` ì²˜ë¦¬ ì‹œ `BytesIO` í™œìš©í•˜ì—¬ ì´ì¤‘ ì†Œë¹„ ë°©ì§€
- New Relic ì»¤ìŠ¤í…€ ì´ë²¤íŠ¸ ì „ì†¡ ì„±ëŠ¥ ê°œì„ 
- `generate_with_model()` ë“± ì‹ ê·œ Bedrock API ì§€ì› ê°•í™”

### v0.3.3
- ì‘ë‹µ ë°ì´í„°ë¥¼ ì†Œë¹„í•˜ì§€ ì•ŠëŠ” ê¸°ëŠ¥ ì¶”ê°€: StreamingBody ê°ì²´ë¥¼ ë³µì œí•˜ì—¬ ì›ë³¸ ë³´ì¡´
- io.BytesIOë¥¼ ì‚¬ìš©í•œ ì‘ë‹µ ìŠ¤íŠ¸ë¦¼ ë³µì‚¬ êµ¬í˜„
- ëª¨ë‹ˆí„°ë§ ë°ì´í„° ì¶”ì¶œ ì‹œ ì›ë³¸ ì‘ë‹µ ê°ì²´ë¥¼ ë³´ì¡´í•˜ëŠ” ë°©ì‹ìœ¼ë¡œ ê°œì„ 
- seek/tell ë©”ì„œë“œë¥¼ í™œìš©í•œ ìŠ¤íŠ¸ë¦¼ ìœ„ì¹˜ ë³µì› ê¸°ëŠ¥ ì¶”ê°€

### v0.3.0
- íŒ©í† ë¦¬ íŒ¨í„´ì„ ì‚¬ìš©í•œ ì´ë²¤íŠ¸ ìƒì„± ë¡œì§ ê°œì„ 
- í…ŒìŠ¤íŠ¸ ì•ˆì •ì„± í–¥ìƒ ë° CI/CD íŒŒì´í”„ë¼ì¸ ê°œì„ 
- ì¬ê·€ í˜¸ì¶œ ë¬¸ì œ í•´ê²°
- `CommonSummaryAttributes` í´ë˜ìŠ¤ ì¶”ê°€ë¡œ ì´ë²¤íŠ¸ ë°ì´í„° í‘œì¤€í™”
- AWS ë¦¬ì „ ì§€ì • í•„ìš”ì„± ëª…ì‹œ
- API í‚¤ê°€ ì—†ëŠ” í™˜ê²½ì—ì„œë„ í…ŒìŠ¤íŠ¸ìš© í‚¤ë¡œ ì‹¤í–‰ ê°€ëŠ¥
- New Relic íŠ¸ëœì­ì…˜ ê´€ë¦¬ ê¸°ëŠ¥ ì¶”ê°€ë¡œ ì´ë²¤íŠ¸ ë¡œê¹… ì•ˆì •ì„± í–¥ìƒ

## ì„¤ì¹˜ ë°©ë²•

### pip ì„¤ì¹˜

```bash
pip install -i https://test.pypi.org/simple/ nr-bedrock-observability
```

### Streamlit ì§€ì› ì¶”ê°€

```bash
pip install -i https://test.pypi.org/simple/ nr-bedrock-observability[streamlit]
```

## ê¸°ë³¸ ì‚¬ìš©ë²•

### 1. AWS Bedrock í´ë¼ì´ì–¸íŠ¸ ëª¨ë‹ˆí„°ë§

```python
import boto3
import json
from nr_bedrock_observability import monitor_bedrock

# Bedrock í´ë¼ì´ì–¸íŠ¸ ìƒì„± (ë°˜ë“œì‹œ ë¦¬ì „ ì§€ì •)
bedrock_client = boto3.client('bedrock-runtime', region_name='ap-northeast-2')

# ëª¨ë‹ˆí„°ë§ ì„¤ì •
monitored_client = monitor_bedrock(bedrock_client, {
    'application_name': 'MyApp',  # í•„ìˆ˜
    'new_relic_api_key': 'YOUR_NEW_RELIC_API_KEY',  # ì„ íƒì  (í™˜ê²½ë³€ìˆ˜ ì‚¬ìš© ê°€ëŠ¥)
})

# í‰ì†Œì²˜ëŸ¼ Bedrock API í˜¸ì¶œ
response = monitored_client.invoke_model(
    modelId='anthropic.claude-3-sonnet-20240229-v1:0',
    body=json.dumps({
        "anthropic_version": "bedrock-2023-05-31",
        "max_tokens": 300,
        "messages": [
            {
                "role": "user",
                "content": [
                    {
                        "type": "text",
                        "text": "ì¸ê³µì§€ëŠ¥ì˜ ì—­ì‚¬ë¥¼ ê°„ëµí•˜ê²Œ ì„¤ëª…í•´ì¤˜."
                    }
                ]
            }
        ],
        "temperature": 0.7
    })
)

# ì‘ë‹µ ì²˜ë¦¬
response_body = json.loads(response['body'].read().decode('utf-8'))
if "content" in response_body and len(response_body["content"]) > 0:
    for content_item in response_body["content"]:
        if content_item["type"] == "text":
            print(content_item["text"])
```

### 2. ìŠ¤íŠ¸ë¦¬ë° API ì‚¬ìš©

```python
import boto3
import json
from nr_bedrock_observability import monitor_bedrock

# Bedrock í´ë¼ì´ì–¸íŠ¸ ìƒì„±
bedrock = boto3.client('bedrock-runtime', region_name='ap-northeast-2')

# ëª¨ë‹ˆí„°ë§ ì„¤ì •
monitored_client = monitor_bedrock(bedrock, {
    'application_name': 'MyStreamingApp',
})

# ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µìœ¼ë¡œ ëª¨ë¸ í˜¸ì¶œ
stream_response = monitored_client.invoke_model_with_response_stream(
    modelId='anthropic.claude-3-sonnet-20240229-v1:0',
    body=json.dumps({
        "anthropic_version": "bedrock-2023-05-31",
        "max_tokens": 300,
        "messages": [
            {
                "role": "user",
                "content": [
                    {
                        "type": "text",
                        "text": "ì¸ê³µì§€ëŠ¥ ë°œì „ì˜ ë¯¸ë˜ì— ëŒ€í•´ ì„¤ëª…í•´ì¤˜."
                    }
                ]
            }
        ],
        "temperature": 0.7
    })
)

# ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ì²˜ë¦¬
for event in stream_response['body']:
    chunk_bytes = event['chunk']['bytes']
    chunk_str = chunk_bytes.decode('utf-8')
    
    try:
        chunk = json.loads(chunk_str)
        if 'content' in chunk and len(chunk['content']) > 0:
            for content_item in chunk['content']:
                if content_item.get('type') == 'text':
                    chunk_text = content_item.get('text', '')
                    print(chunk_text, end='', flush=True)
    except json.JSONDecodeError:
        print(f"JSON íŒŒì‹± ì˜¤ë¥˜: {chunk_str}")
```

### 3. ì‚¬ìš©ì í”¼ë“œë°± ìˆ˜ì§‘

```python
import boto3
import json
from nr_bedrock_observability import monitor_bedrock

# í”¼ë“œë°± ì½œë°± í•¨ìˆ˜ ì •ì˜
def feedback_callback(input_text, output_text):
    """ì‚¬ìš©ìë¡œë¶€í„° í”¼ë“œë°±ì„ ìˆ˜ì§‘í•˜ëŠ” ì½œë°± í•¨ìˆ˜"""
    # ì—¬ê¸°ì„œ ì‹¤ì œë¡œëŠ” UIì—ì„œ ì‚¬ìš©ìë¡œë¶€í„° í”¼ë“œë°±ì„ ìˆ˜ì§‘
    # ì˜ˆì œì—ì„œëŠ” í•˜ë“œì½”ë”©ëœ ê°’ ë°˜í™˜
    return {
        'feedback': 'positive',  # 'positive', 'negative', 'neutral'
        'sentiment': 0.8,  # -1.0ì—ì„œ 1.0 ì‚¬ì´ì˜ ê°’
        'feedback_message': 'ë‹µë³€ì´ ë§¤ìš° ìœ ìš©í–ˆìŠµë‹ˆë‹¤.'
    }

# Bedrock í´ë¼ì´ì–¸íŠ¸ ìƒì„±
bedrock = boto3.client('bedrock-runtime', region_name='ap-northeast-2')

# ëª¨ë‹ˆí„°ë§ ì„¤ì • - í”¼ë“œë°± ìˆ˜ì§‘ í™œì„±í™”
monitored_client = monitor_bedrock(bedrock, {
    'application_name': 'MyFeedbackApp',
    'collect_feedback': True,  # í”¼ë“œë°± ìˆ˜ì§‘ í™œì„±í™”
    'feedback_callback': feedback_callback  # í”¼ë“œë°± ì½œë°± í•¨ìˆ˜ ì§€ì •
})

# ëª¨ë¸ í˜¸ì¶œ
response = monitored_client.invoke_model(
    modelId='anthropic.claude-3-sonnet-20240229-v1:0',
    body=json.dumps({
        "anthropic_version": "bedrock-2023-05-31",
        "max_tokens": 300,
        "messages": [
            {
                "role": "user",
                "content": [
                    {
                        "type": "text",
                        "text": "ë¨¸ì‹ ëŸ¬ë‹ê³¼ ë”¥ëŸ¬ë‹ì˜ ì°¨ì´ì ì€ ë¬´ì—‡ì¸ê°€ìš”?"
                    }
                ]
            }
        ],
        "temperature": 0.7
    })
)

# ì‘ë‹µ ì²˜ë¦¬
response_body = json.loads(response['body'].read().decode('utf-8'))
if "content" in response_body and len(response_body["content"]) > 0:
    for content_item in response_body["content"]:
        if content_item["type"] == "text":
            print(content_item["text"])
```

### 4. RAG ì›Œí¬í”Œë¡œìš° ëª¨ë‹ˆí„°ë§

```python
import boto3
import json
import newrelic.agent
from nr_bedrock_observability import monitor_bedrock, monitor_opensearch_results, link_rag_workflow

# Bedrock í´ë¼ì´ì–¸íŠ¸ ìƒì„±
bedrock = boto3.client('bedrock-runtime', region_name='ap-northeast-2')

# ëª¨ë‹ˆí„°ë§ ì„¤ì •
monitored_client = monitor_bedrock(bedrock, {
    'application_name': 'MyRagApp',
})

# ì‚¬ìš©ì ì§ˆë¬¸
user_query = "ì¸ê³µì§€ëŠ¥ ìœ¤ë¦¬ì— ëŒ€í•´ ì„¤ëª…í•´ì£¼ì„¸ìš”."

# OpenSearch ê²€ìƒ‰ (ê°€ìƒ ì˜ˆì œ)
opensearch_results = [
    {
        'title': 'AI ìœ¤ë¦¬ ì†Œê°œ',
        'content': 'AI ìœ¤ë¦¬ëŠ” ì¸ê³µì§€ëŠ¥ ê¸°ìˆ ì˜ ê°œë°œê³¼ ì‚¬ìš©ì— ê´€ë ¨ëœ ìœ¤ë¦¬ì  ê³ ë ¤ì‚¬í•­ì„ ë‹¤ë£¹ë‹ˆë‹¤.',
        'score': 0.95
    },
    {
        'title': 'AI í¸í–¥ì„± ë¬¸ì œ',
        'content': 'ì¸ê³µì§€ëŠ¥ ì‹œìŠ¤í…œì˜ í¸í–¥ì„± ë¬¸ì œëŠ” í›ˆë ¨ ë°ì´í„°ì— ì¡´ì¬í•˜ëŠ” ì‚¬íšŒì  í¸ê²¬ì´ ë°˜ì˜ë  ìˆ˜ ìˆë‹¤ëŠ” ì ì…ë‹ˆë‹¤.',
        'score': 0.85
    }
]

# OpenSearch ê²°ê³¼ë¥¼ NewRelicì— ê¸°ë¡
monitor_opensearch_results(
    opensearch_client=None,  # ì‹¤ì œë¡œëŠ” OpenSearch í´ë¼ì´ì–¸íŠ¸
    query=user_query,
    results=opensearch_results,
    application_name='MyRagApp'
)

# Bedrock ìš”ì²­ êµ¬ì„±
request = {
    'modelId': 'anthropic.claude-3-sonnet-20240229-v1:0',
    'body': json.dumps({
        "anthropic_version": "bedrock-2023-05-31",
        "max_tokens": 500,
        "messages": [
            {
                "role": "system",
                "content": "ì£¼ì–´ì§„ ì»¨í…ìŠ¤íŠ¸ì— ê¸°ë°˜í•˜ì—¬ ì •í™•í•˜ê²Œ ë‹µë³€í•´ì£¼ì„¸ìš”."
            },
            {
                "role": "user",
                "content": [
                    {
                        "type": "text",
                        "text": f"""
                        ë‹¤ìŒ ì •ë³´ì— ê¸°ë°˜í•˜ì—¬ ì§ˆë¬¸ì— ë‹µë³€í•´ì£¼ì„¸ìš”:
                        
                        ì»¨í…ìŠ¤íŠ¸:
                        - ì œëª©: AI ìœ¤ë¦¬ ì†Œê°œ
                          ë‚´ìš©: AI ìœ¤ë¦¬ëŠ” ì¸ê³µì§€ëŠ¥ ê¸°ìˆ ì˜ ê°œë°œê³¼ ì‚¬ìš©ì— ê´€ë ¨ëœ ìœ¤ë¦¬ì  ê³ ë ¤ì‚¬í•­ì„ ë‹¤ë£¹ë‹ˆë‹¤.
                        
                        - ì œëª©: AI í¸í–¥ì„± ë¬¸ì œ
                          ë‚´ìš©: ì¸ê³µì§€ëŠ¥ ì‹œìŠ¤í…œì˜ í¸í–¥ì„± ë¬¸ì œëŠ” í›ˆë ¨ ë°ì´í„°ì— ì¡´ì¬í•˜ëŠ” ì‚¬íšŒì  í¸ê²¬ì´ ë°˜ì˜ë  ìˆ˜ ìˆë‹¤ëŠ” ì ì…ë‹ˆë‹¤.
                        
                        ì§ˆë¬¸: {user_query}
                        """
                    }
                ]
            }
        ],
        "temperature": 0.7
    })
}

# RAG ì›Œí¬í”Œë¡œìš° ì—°ê²° (íŠ¸ë ˆì´ìŠ¤ ID ìƒì„± ë° OpenSearch ê²°ê³¼ ê¸°ë¡)
trace_id = link_rag_workflow(
    user_query=user_query,
    opensearch_results=opensearch_results,
    bedrock_client=monitored_client,
    bedrock_request=request,
    application_name='MyRagApp'
)

# Claude 3 í˜¸ì¶œ (íŠ¸ë ˆì´ìŠ¤ IDì™€ ì»¨í…ìŠ¤íŠ¸ê°€ ìë™ìœ¼ë¡œ ì—°ê²°ë¨)
response = monitored_client.invoke_model(**request)

# ì‘ë‹µ ì²˜ë¦¬
response_body = json.loads(response['body'].read().decode('utf-8'))
if "content" in response_body and len(response_body["content"]) > 0:
    for content_item in response_body["content"]:
        if content_item["type"] == "text":
            print(content_item["text"])

print(f"íŠ¸ë ˆì´ìŠ¤ ID: {trace_id}")  # New Relicì—ì„œ íŠ¸ë ˆì´ìŠ¤ í™•ì¸ ì‹œ ì‚¬ìš©
```

### 5. Streamlitì—ì„œ í”¼ë“œë°± ìˆ˜ì§‘

```python
import streamlit as st
import boto3
import json
import uuid
from nr_bedrock_observability import monitor_bedrock, create_feedback_collector

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(page_title="Bedrock í”¼ë“œë°± ë°ëª¨", page_icon="ğŸ¤–")

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
if "trace_id" not in st.session_state:
    st.session_state.trace_id = str(uuid.uuid4())
if "messages" not in st.session_state:
    st.session_state.messages = []
if "current_completion_id" not in st.session_state:
    st.session_state.current_completion_id = None

# Bedrock í´ë¼ì´ì–¸íŠ¸ ì„¤ì •
@st.cache_resource
def get_bedrock_client(region_name='ap-northeast-2'):
    bedrock_client = boto3.client('bedrock-runtime', region_name=region_name)
    return monitor_bedrock(bedrock_client, {
        'application_name': 'Streamlit-Feedback-Demo',
    })

# í”¼ë“œë°± ìˆ˜ì§‘ê¸° ìƒì„±
@st.cache_resource
def get_feedback_collector():
    return create_feedback_collector(
        application_name='Streamlit-Feedback-Demo',
        trace_id=st.session_state.trace_id
    )

# ë©”ì¸ UI
st.title("ğŸ¤– AWS Bedrock ì±„íŒ… + í”¼ë“œë°± ë°ëª¨")

# ëŒ€í™” ê¸°ë¡ í‘œì‹œ
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# ì‚¬ìš©ì ì…ë ¥
user_input = st.chat_input("ë¬´ì—‡ì´ë“  ë¬¼ì–´ë³´ì„¸ìš”!")

if user_input:
    # ì‚¬ìš©ì ë©”ì‹œì§€ í‘œì‹œ ë° ì €ì¥
    st.session_state.messages.append({"role": "user", "content": user_input})
    with st.chat_message("user"):
        st.markdown(user_input)
    
    # ì™„ì„± ID ìƒì„±
    completion_id = str(uuid.uuid4())
    st.session_state.current_completion_id = completion_id
    
    # í”¼ë“œë°± ìˆ˜ì§‘ê¸° ì„¤ì •
    feedback_collector = get_feedback_collector()
    feedback_collector.update_completion_id(completion_id)
    
    # ëª¨ë¸ ì‘ë‹µ ìƒì„±
    with st.chat_message("assistant"):
        with st.spinner("ìƒê° ì¤‘..."):
            try:
                # Bedrock í˜¸ì¶œ
                bedrock = get_bedrock_client()
                response = bedrock.invoke_model(
                    modelId='anthropic.claude-3-sonnet-20240229-v1:0',
                    body=json.dumps({
                        "anthropic_version": "bedrock-2023-05-31",
                        "max_tokens": 500,
                        "messages": [
                            {"role": "system", "content": "ë‹¹ì‹ ì€ ë„ì›€ì´ ë˜ëŠ” AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤."},
                            *[{"role": m["role"], "content": m["content"]} for m in st.session_state.messages]
                        ],
                        "temperature": 0.7
                    })
                )
                
                # ì‘ë‹µ ì²˜ë¦¬
                response_body = json.loads(response['body'].read().decode('utf-8'))
                assistant_response = ""
                
                if "content" in response_body and len(response_body["content"]) > 0:
                    for content_item in response_body["content"]:
                        if content_item["type"] == "text":
                            assistant_response += content_item["text"]
                
                # ì‘ë‹µ í‘œì‹œ ë° ì €ì¥
                st.markdown(assistant_response)
                st.session_state.messages.append({"role": "assistant", "content": assistant_response})
                
                # í”¼ë“œë°± UI í‘œì‹œ
                st.subheader("ì‘ë‹µ í‰ê°€")
                feedback_collector.render_feedback_ui(key=f"feedback_{completion_id}")
                
            except Exception as e:
                st.error(f"ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
```

## ì´ˆê¸°í™” ì˜µì…˜

```python
monitor_options = {
    # í•„ìˆ˜ ì˜µì…˜
    'application_name': 'MyApp',  # New Relicì—ì„œ ì‚¬ìš©í•  ì• í”Œë¦¬ì¼€ì´ì…˜ ì´ë¦„
    
    # ì„ íƒì  ì˜µì…˜
    'new_relic_api_key': 'YOUR_NEW_RELIC_API_KEY',  # í™˜ê²½ ë³€ìˆ˜ë¡œë„ ì„¤ì • ê°€ëŠ¥
    'host': 'custom.endpoint.com',  # ì´ë²¤íŠ¸ ì—”ë“œí¬ì¸íŠ¸ ì˜¤ë²„ë¼ì´ë“œ
    'port': 443,  # íŠ¸ë ˆì´ìŠ¤ ì—”ë“œí¬ì¸íŠ¸ í¬íŠ¸ ì˜¤ë²„ë¼ì´ë“œ
    'track_token_usage': True,  # í† í° ì‚¬ìš©ëŸ‰ ì¶”ì  (ê¸°ë³¸ê°’: True)
    'disable_streaming_events': False,  # ìŠ¤íŠ¸ë¦¬ë° ì´ë²¤íŠ¸ ë¹„í™œì„±í™” (ê¸°ë³¸ê°’: False)
    'collect_feedback': False,  # í”¼ë“œë°± ìˆ˜ì§‘ í™œì„±í™” (ê¸°ë³¸ê°’: False)
    'feedback_callback': my_feedback_function  # í”¼ë“œë°± ì½œë°± í•¨ìˆ˜
}
```

## í™˜ê²½ ë³€ìˆ˜

ë‹¤ìŒ í™˜ê²½ ë³€ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì—¬ API í‚¤ë¥¼ ì„¤ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:

- `NEW_RELIC_LICENSE_KEY` - ìš”ì²­ ì¸ì¦ì— ì‚¬ìš©ë˜ëŠ” API í‚¤
- `NEW_RELIC_INSERT_KEY` - API í‚¤ì™€ ë™ì¼
- `EVENT_CLIENT_HOST` - ì´ë²¤íŠ¸ ì—”ë“œí¬ì¸íŠ¸ í˜¸ìŠ¤íŠ¸ ì˜¤ë²„ë¼ì´ë“œ

## ì§€ì›ë˜ëŠ” ëª¨ë¸

ë‹¤ìŒì„ í¬í•¨í•œ ëª¨ë“  AWS Bedrock ëª¨ë¸ì„ ì§€ì›í•©ë‹ˆë‹¤:

### Amazon Titan ëª¨ë¸
- Titan Text (Lite, Express, Premier)
- Titan Text V2 (Lite, Express, Premier)
- Titan Embeddings
- Titan Multimodal

### Anthropic Claude ëª¨ë¸
- Claude 1 ë° 2
- Claude Instant
- Claude 3 (Haiku, Sonnet, Opus)
- Claude 3.5 Sonnet

### AI21 Labs, Cohere, Meta, Mistral ëª¨ë¸
- Jurassic-2, Jamba
- Command, Command Light, Command R/R Plus, Embed
- Llama 2 (13B, 70B), Llama 3 (8B, 70B)
- Mistral, Mixtral, Mistral Small/Medium/Large

## New Relic ë°ì´í„° ë¶„ì„

New Relic UIì—ì„œ ë‹¤ìŒ NRQL ì¿¼ë¦¬ë¥¼ ì‚¬ìš©í•˜ì—¬ ë°ì´í„°ë¥¼ ë¶„ì„í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:

### ê¸°ë³¸ ë¶„ì„ ì¿¼ë¦¬

```sql
-- ëª¨ë“  LLM ì™„ì„± ì´ë²¤íŠ¸ ì¡°íšŒ
FROM LlmChatCompletionSummary LIMIT 100

-- ì‘ë‹µ ì‹œê°„ ë¶„í¬ í™•ì¸
FROM LlmChatCompletionSummary SELECT average(response_time), percentile(response_time, 95, 99) TIMESERIES

-- ëª¨ë¸ë³„ ì‚¬ìš©ëŸ‰ ë¶„ì„
FROM LlmChatCompletionSummary FACET request_model LIMIT 10

-- ì˜¤ë¥˜ ë¶„ì„
FROM LlmChatCompletionSummary WHERE error_message IS NOT NULL FACET error_type LIMIT 10
```

### RAG ì›Œí¬í”Œë¡œìš° ë¶„ì„ ì¿¼ë¦¬

```sql
-- ì „ì²´ RAG ì›Œí¬í”Œë¡œìš° ë³´ê¸°
FROM Span WHERE rag.workflow = 'true' FACET name LIMIT 100

-- ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ì¡°íšŒ
FROM LlmSystemPrompt LIMIT 100

-- ì‚¬ìš©ì í”„ë¡¬í”„íŠ¸ ì¡°íšŒ
FROM LlmUserPrompt LIMIT 100

-- OpenSearch ê²°ê³¼ ì¡°íšŒ
FROM LlmOpenSearchResult LIMIT 100

-- RAG ì»¨í…ìŠ¤íŠ¸ ì¡°íšŒ
FROM LlmRagContext LIMIT 100

-- ì±„íŒ… ë©”ì‹œì§€ ì—­í• ë³„ ì¡°íšŒ
FROM LlmChatCompletionMessage FACET role LIMIT 100
```

### í”¼ë“œë°± ë¶„ì„ ì¿¼ë¦¬

```sql
-- ëª¨ë“  í”¼ë“œë°± ì¡°íšŒ
FROM LlmFeedback LIMIT 100

-- ê¸ì •/ë¶€ì • í”¼ë“œë°± ë¹„ìœ¨ í™•ì¸
FROM LlmFeedback FACET feedback LIMIT 10

-- í‰ê·  ê°ì • ì ìˆ˜ í™•ì¸
FROM LlmFeedback SELECT average(sentiment) TIMESERIES

-- íŠ¹ì • íŠ¸ë ˆì´ìŠ¤ì˜ í”¼ë“œë°± í™•ì¸
FROM LlmFeedback WHERE trace_id = 'your-trace-id' LIMIT 10
```

## ê°œë°œ ë° ê¸°ì—¬

### í…ŒìŠ¤íŠ¸ ì‹¤í–‰

```bash
pip install -e ".[dev]"
pytest
```

### ë¡œì»¬ì—ì„œ ë¹Œë“œí•˜ê¸°

```bash
pip install build
python -m build
```

ëª¨ë“  API í˜¸ì¶œê³¼ í”¼ë“œë°± ë°ì´í„°ê°€ ìë™ìœ¼ë¡œ New Relicì— ì „ì†¡ë˜ì–´ LLM ì‘ìš© í”„ë¡œê·¸ë¨ì˜ ì„±ëŠ¥ê³¼ ì‚¬ìš©ì ë§Œì¡±ë„ë¥¼ í¬ê´„ì ìœ¼ë¡œ ëª¨ë‹ˆí„°ë§í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

